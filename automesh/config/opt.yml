Adam:
  obj: !!python/name:torch.optim.adam.Adam ''
  params:
    lr: basic
    weight_decay:
    - 0.0
    - 0.00001
    - 0.00002
    - 0.00004
    - 0.00008
    - 0.00016